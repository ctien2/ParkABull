# Auto-Export Video Parking Detector

## ğŸ“‹ Overview
This script automatically processes an entire parking lot video, applies computer vision detection, and exports an annotated output video with all detections visible.

## ğŸ†š Difference from Original Script

| Feature | Original Script | Auto-Export Script |
|---------|----------------|-------------------|
| **Pausing** | Manual - waits for user input | Automatic - shows message for 2 seconds then continues |
| **Output** | Live display only | Saves full annotated video file |
| **Interaction** | Press SPACE to continue | Fully automatic, hands-free |
| **Use Case** | Live monitoring | Creating demo videos |
| **Speed** | Configurable slow motion | Slow motion during playback, normal in export |

## ğŸ¬ What It Does

1. **Reads** your parking lot video
2. **Analyzes** frames every 1 second with the AI model
3. **Draws** green boxes (FREE) and red boxes (OCCUPIED) on parking spots
4. **Shows** pause messages ("ANALYZING FRAME...") for 2 seconds
5. **Continues** automatically without user input
6. **Exports** complete annotated video with:
   - Bounding boxes on all parking spots
   - Live stats overlay (FREE/OCCUPIED/TOTAL)
   - Slow motion effect
   - Pause messages between analyses

## ğŸš€ How to Run

```bash
cd computer_vision
python video_parking_detector_auto_export.py
```

## âš™ï¸ Configuration

Edit these settings at the top of the file:

```python
VIDEO_PATH = "parking_lot_video.mp4"  # Your input video
OUTPUT_VIDEO_PATH = "output_annotated_parking_video.mp4"  # Output file
FRAME_INTERVAL = 1  # Analyze every N seconds
PLAYBACK_SPEED = 0.25  # 0.25 = 1/4 speed (slow motion)
AUTO_UNPAUSE_DELAY = 2  # Pause message duration in seconds
EXPORT_FPS = 30  # Output video frame rate
```

## ğŸ“Š Output Files

After running, you'll get:

1. **`output_annotated_parking_video.mp4`** - Main output video with annotations
2. **`video_frames/`** - Individual analyzed frame images
3. **`video_detection_results.txt`** - Text log of all detections
4. **`live_parking_data.json`** - Latest parking data (for web integration)

## ğŸ¥ Output Video Features

The exported video includes:
- âœ… **Green boxes** around FREE parking spots
- ğŸš— **Red boxes** around OCCUPIED parking spots
- ğŸ“Š **Stats overlay** showing:
  - FREE: X
  - OCCUPIED: Y
  - TOTAL: Z
- â¸ï¸ **"ANALYZING FRAME..." messages** with 2-second pauses
- ğŸ¬ **Slow motion** effect for easy viewing
- ğŸ·ï¸ **Labels** on each parking spot

## ğŸ“ˆ Progress Tracking

While running, you'll see:
```
ğŸ“¸ Snapshot 1 captured at 2025-11-08_23-45-30
ğŸ” Analyzing: video_frames/frame_0001_2025-11-08_23-45-30.jpg
   âœ… Free spots: 87
   ğŸš— Occupied spots: 63
   ğŸ…¿ï¸  Total spots: 150
Progress: 15.3% (459/3000 frames)
```

## â±ï¸ Processing Time

Depends on:
- Video length
- Frame interval (analyzing every 1 second vs 3 seconds)
- Internet speed (API calls to Roboflow)
- Computer performance

**Example:** 
- 5-minute video at 30fps = 9,000 frames
- Analyzing every 1 second = ~300 API calls
- Estimated time: 10-15 minutes

## ğŸ¯ Use Cases

### 1. Demo Videos
Create impressive demo videos showing your parking detection system in action.

### 2. Accuracy Verification
Watch the entire video to verify model accuracy across different conditions.

### 3. Presentations
Export and use in presentations, pitches, or documentation.

### 4. Social Media
Create shareable content showing your computer vision project.

### 5. Documentation
Visual documentation of how your system performs.

## ğŸ›‘ Early Exit

Press **'Q'** during processing to stop early and save a partial video.

## ğŸ’¡ Tips

### Speed Up Processing
```python
FRAME_INTERVAL = 3  # Analyze less frequently
AUTO_UNPAUSE_DELAY = 1  # Shorter pause messages
```

### Slow Down Playback More
```python
PLAYBACK_SPEED = 0.1  # Very slow (1/10 speed)
```

### Higher Quality Export
```python
EXPORT_FPS = 60  # Smoother output video
```

### Smaller File Size
```python
# Use H.264 codec (edit line 232):
fourcc = cv2.VideoWriter_fourcc(*'avc1')
```

## ğŸ› Troubleshooting

### Video Won't Play
Try a different codec. Edit line 232:
```python
# Instead of 'mp4v', try:
fourcc = cv2.VideoWriter_fourcc(*'XVID')  # .avi format
# Or:
fourcc = cv2.VideoWriter_fourcc(*'avc1')  # H.264
```

### Processing Too Slow
- Increase `FRAME_INTERVAL` (analyze less frequently)
- Use a shorter video for testing
- Check internet connection (API calls)

### Output Video Too Large
- Lower `EXPORT_FPS` (e.g., 24 instead of 30)
- Use better codec (H.264 instead of mp4v)
- Reduce input video resolution

### Model Not Detecting Well
- See main README for model accuracy tips
- Check video quality and lighting
- Verify camera angle

## ğŸ“ Example Output

After completion:
```
============================================================
âœ… Processing complete!
ğŸ“Š Total snapshots analyzed: 150
ğŸ“ Frames saved in: video_frames
ğŸ“„ Results log: video_detection_results.txt
ğŸ¬ Output video: output_annotated_parking_video.mp4
ğŸ“ Video stats: 9000 frames processed
============================================================

ğŸ“¦ Output video size: 245.67 MB
ğŸ¥ You can play the video: output_annotated_parking_video.mp4
```

## ğŸ¬ Viewing the Output

Open with any video player:
- VLC Media Player
- QuickTime (Mac)
- Windows Media Player
- Browser (HTML5 video)

## ğŸ”„ Batch Processing

To process multiple videos, edit the end of the script:
```python
videos = ["video1.mp4", "video2.mp4", "video3.mp4"]
for video in videos:
    process_video_auto_export(video)
```

## âœ¨ Next Steps

- Share your output video!
- Use it in presentations
- Post on social media
- Include in documentation
- Show to potential users/investors
